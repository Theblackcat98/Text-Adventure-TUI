Metadata-Version: 2.1
Name: text-adventure-tui
Version: 0.1.1
Summary: A dynamic text adventure game for your terminal, powered by Ollama LLMs.
Home-page: https://github.com/Theblackcat98/Text-Adventure-TUI
Author: The Black Cat Codes
Author-email: author@example.com
License: MIT
Project-URL: Bug Tracker, https://github.com/Theblackcat98/Text-Adventure-TUI/issues
Project-URL: Source Code, https://github.com/Theblackcat98/Text-Adventure-TUI
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: End Users/Desktop
Classifier: Topic :: Games/Entertainment :: Interactive Fiction
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Operating System :: OS Independent
Classifier: Environment :: Console
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: ollama<0.3.0,>=0.1.0
Requires-Dist: rich<14.0.0,>=10.0.0
Requires-Dist: PyYAML<7.0,>=5.0

# Terminal Text Adventure

Welcome to **Terminal Text Adventure**! This is an interactive fiction game played in your terminal, where the story and choices are dynamically generated by a Large Language Model (LLM) powered by Ollama.

## Features

*   **Dynamic Storytelling:** Every playthrough can be unique as the story adapts to your choices.
*   **LLM-Powered:** Utilizes Ollama and a compatible model (e.g., `phi4:latest`) to generate immersive narratives and engaging options.
*   **Rich Terminal Interface:** Uses the `rich` library for a visually appealing and user-friendly experience in the terminal.
*   **Extensible:** New starting points for stories can be added easily.

## Prerequisites

Before you can play, you need to have Ollama installed and running with a suitable model.

1.  **Install Ollama:**
    *   Follow the instructions on the [official Ollama website](https://ollama.com/download).
2.  **Pull a Model:**
    *   Once Ollama is running, pull a model. This game is tested with `phi4:latest`. You can pull it using the command:
        ```bash
        ollama pull phi4:latest
        ```
    *   Ensure the Ollama server is running (usually `ollama serve` or by starting the Ollama application). By default, it runs on `http://localhost:11434`.

## Installation

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/Theblackcat98/Text-Adventure-TUI.git
    cd Text-Adventure-TUI
    ```
2.  **Create a Virtual Environment (Recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```
3.  **Install Dependencies:**
    The game requires the `ollama` and `rich` Python libraries.
    ```bash
    pip install ollama rich
    ```
    Alternatively, if you have cloned the repository and want to install it as a package (e.g., for development or to use the `terminal-adventure` command):
    ```bash
    pip install .
    # or for an editable install
    pip install -e .
    ```

## How to Play

1.  **Ensure Ollama is Running:**
    Make sure your Ollama server is active and the model (e.g., `phi4:latest`) is available. The game defaults to connecting to `http://localhost:11434` and using the `phi4:latest` model. These can be configured via environment variables (see Configuration).

2.  **Run the Game:**
    Navigate to the project directory and run:
    ```bash
    python game.py
    ```
    Or, if you installed the package using `pip install .` or `pip install -e .`, you can run:
    ```bash
    terminal-adventure
    ```

3.  **Interact with the Story:**
    *   The game will present you with a story segment.
    *   You will then be given a list of choices.
    *   Enter the number corresponding to your desired choice and press Enter.
    *   Type `quit` at any choice prompt to exit the game.

## Configuration

You can configure the Ollama host and model using environment variables:

*   `OLLAMA_HOST`: The URL of your Ollama server (e.g., `http://localhost:11434`).
*   `OLLAMA_MODEL`: The name of the Ollama model to use (e.g., `phi4:latest`, `llama3:latest`).

**Example:**
```bash
export OLLAMA_HOST="http://127.0.0.1:11434"
export OLLAMA_MODEL="llama3:latest"
python game.py
```

## Game Structure

*   `game.py`: Main game logic, LLM interaction, and terminal interface.
*   `story_parts/`: Contains text files for initial story segments.
    *   `01_intro.txt`: The default starting point for the adventure.

## Contributing

Contributions are welcome! If you have ideas for improvements, new features, or bug fixes, please feel free to:

1.  Fork the repository.
2.  Create a new branch for your feature (`git checkout -b feature/amazing-feature`).
3.  Commit your changes (`git commit -m 'Add some amazing feature'`).
4.  Push to the branch (`git push origin feature/amazing-feature`).
5.  Open a Pull Request.

## Future Enhancements

*   More sophisticated state management.
*   Ability to save and load games.
*   Wider variety of starting scenarios.
*   More robust error handling and LLM interaction management.

## Publishing to PyPI (For Maintainers)

This section is for maintainers who want to publish the package to the Python Package Index (PyPI).

1.  **Update `setup.py`**:
    *   Ensure `version` is updated for the new release.
    *   Verify/update `author`, `author_email`, and `url`.
    *   Confirm the `LICENSE` file is correct and the license classifier in `setup.py` matches.

2.  **Install Build Tools**:
    ```bash
    pip install build twine
    ```

3.  **Clean Previous Builds (Optional)**:
    ```bash
    rm -rf build dist *.egg-info
    ```

4.  **Build Distribution Files**:
    ```bash
    python -m build
    ```
    This will create a `dist` directory with a `.tar.gz` (source distribution) and a `.whl` (wheel) file.

5.  **Check Distribution Files (Optional but Recommended)**:
    ```bash
    twine check dist/*
    ```

6.  **Upload to TestPyPI (Recommended First Step)**:
    *   Ensure you have a TestPyPI account and API token.
    *   Configure your `~/.pypirc` file or use token authentication.
    ```bash
    twine upload --repository testpypi dist/*
    ```
    *   Install from TestPyPI to verify:
    ```bash
    pip install --index-url https://test.pypi.org/simple/ --no-deps terminal-text-adventure
    ```

7.  **Upload to PyPI (Production)**:
    *   Ensure you have a PyPI account and API token.
    ```bash
    twine upload dist/*
    ```

---

Enjoy your adventure!
